"""
LLM Provider Examples - å¤šç§ LLM æä¾›å•†ç¤ºä¾‹
===========================================

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„ LLM æä¾›å•†ï¼š
1. OpenAI
2. Azure OpenAI â­
3. Anthropic Claude
4. æœ¬åœ° Ollama

Azure OpenAI é…ç½®æŒ‡å—ï¼š
- åœ¨ Azure Portal åˆ›å»º OpenAI èµ„æº
- éƒ¨ç½²ä¸€ä¸ªæ¨¡å‹ï¼ˆå¦‚ gpt-4oï¼‰
- è·å– endpoint å’Œ API key
"""

import os
import sys
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from dotenv import load_dotenv
load_dotenv()


# ==========================================
# æ–¹å¼ 1: ç›´æ¥ä½¿ç”¨ LangChain
# ==========================================

def get_azure_openai_direct():
    """
    ç›´æ¥ä½¿ç”¨ LangChain çš„ AzureChatOpenAI
    
    éœ€è¦è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š
    - AZURE_OPENAI_API_KEY
    - AZURE_OPENAI_ENDPOINT
    - AZURE_OPENAI_DEPLOYMENT (éƒ¨ç½²åç§°)
    """
    from langchain_openai import AzureChatOpenAI
    
    llm = AzureChatOpenAI(
        # Azure èµ„æºçš„ endpoint
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        # API å¯†é’¥
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        # éƒ¨ç½²åç§°ï¼ˆä¸æ˜¯æ¨¡å‹åç§°ï¼ï¼‰
        deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o"),
        # API ç‰ˆæœ¬
        api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01"),
        # æ¸©åº¦å‚æ•°
        temperature=0,
    )
    
    return llm


def get_openai_direct():
    """ç›´æ¥ä½¿ç”¨ OpenAI"""
    from langchain_openai import ChatOpenAI
    
    llm = ChatOpenAI(
        model=os.getenv("OPENAI_MODEL", "gpt-4o"),
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0,
    )
    
    return llm


# ==========================================
# æ–¹å¼ 2: ä½¿ç”¨é¡¹ç›®çš„ç»Ÿä¸€å·¥å‚
# ==========================================

def get_llm_from_factory(provider: str = "azure"):
    """
    ä½¿ç”¨ shared/llm_providers.py çš„ç»Ÿä¸€å·¥å‚
    
    æ”¯æŒ: "openai", "azure", "anthropic"
    """
    try:
        from shared.llm_providers import get_llm
        return get_llm(provider=provider)
    except ImportError:
        print("è¯·ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ")
        return None


# ==========================================
# æµ‹è¯•å‡½æ•°
# ==========================================

def test_llm(llm, provider_name: str):
    """æµ‹è¯• LLM æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print(f"\n{'='*50}")
    print(f"Testing {provider_name}")
    print('='*50)
    
    try:
        response = llm.invoke("Say 'Hello from Azure!' in Chinese")
        print(f"âœ… Response: {response.content}")
        return True
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False


# ==========================================
# åœ¨ LangGraph ä¸­ä½¿ç”¨ Azure OpenAI
# ==========================================

def langgraph_with_azure_example():
    """
    åœ¨ LangGraph ä¸­ä½¿ç”¨ Azure OpenAI
    """
    from typing import TypedDict
    from langgraph.graph import StateGraph, END
    from langchain_core.messages import HumanMessage, AIMessage
    
    # è·å– Azure OpenAI LLM
    llm = get_azure_openai_direct()
    
    class ChatState(TypedDict):
        messages: list
        response: str
    
    def chat_node(state: ChatState) -> ChatState:
        """ä½¿ç”¨ Azure OpenAI èŠå¤©"""
        messages = state["messages"]
        
        # è°ƒç”¨ Azure OpenAI
        response = llm.invoke(messages)
        
        state["response"] = response.content
        state["messages"].append(AIMessage(content=response.content))
        
        return state
    
    # æ„å»ºå›¾
    workflow = StateGraph(ChatState)
    workflow.add_node("chat", chat_node)
    workflow.set_entry_point("chat")
    workflow.add_edge("chat", END)
    
    app = workflow.compile()
    
    # è¿è¡Œ
    result = app.invoke({
        "messages": [HumanMessage(content="ä½ å¥½ï¼Œè¯·ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹ Azure OpenAI")],
        "response": ""
    })
    
    print("\n" + "="*50)
    print("LangGraph + Azure OpenAI Result:")
    print("="*50)
    print(result["response"])


# ==========================================
# Main
# ==========================================

def main():
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘        LLM Provider Configuration Guide                  â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                           â•‘
    â•‘  Azure OpenAI é…ç½®æ­¥éª¤ï¼š                                   â•‘
    â•‘                                                           â•‘
    â•‘  1. åœ¨ Azure Portal åˆ›å»º OpenAI èµ„æº                      â•‘
    â•‘  2. åœ¨èµ„æºä¸­éƒ¨ç½²æ¨¡å‹ï¼ˆå¦‚ gpt-4o, gpt-4-turboï¼‰            â•‘
    â•‘  3. è·å– endpoint å’Œ API key                              â•‘
    â•‘  4. å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å…¥ï¼š                    â•‘
    â•‘                                                           â•‘
    â•‘     AZURE_OPENAI_API_KEY=your-key                        â•‘
    â•‘     AZURE_OPENAI_ENDPOINT=https://xxx.openai.azure.com/  â•‘
    â•‘     AZURE_OPENAI_DEPLOYMENT=your-deployment-name         â•‘
    â•‘     AZURE_OPENAI_API_VERSION=2024-02-01                  â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    azure_key = os.getenv("AZURE_OPENAI_API_KEY")
    azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    print("\nğŸ“‹ Environment Check:")
    print(f"   AZURE_OPENAI_API_KEY: {'âœ… Set' if azure_key else 'âŒ Not set'}")
    print(f"   AZURE_OPENAI_ENDPOINT: {'âœ… Set' if azure_endpoint else 'âŒ Not set'}")
    print(f"   OPENAI_API_KEY: {'âœ… Set' if openai_key else 'âŒ Not set'}")
    
    # æµ‹è¯• Azure OpenAIï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    if azure_key and azure_endpoint:
        print("\nğŸ”„ Testing Azure OpenAI...")
        try:
            llm = get_azure_openai_direct()
            test_llm(llm, "Azure OpenAI")
            
            # è¿è¡Œ LangGraph ç¤ºä¾‹
            print("\nğŸ”„ Running LangGraph + Azure OpenAI example...")
            langgraph_with_azure_example()
            
        except Exception as e:
            print(f"âŒ Azure OpenAI test failed: {e}")
    else:
        print("\nâš ï¸ Azure OpenAI not configured. Please set environment variables.")
    
    # æµ‹è¯• OpenAIï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    if openai_key and not (azure_key and azure_endpoint):
        print("\nğŸ”„ Testing OpenAI...")
        try:
            llm = get_openai_direct()
            test_llm(llm, "OpenAI")
        except Exception as e:
            print(f"âŒ OpenAI test failed: {e}")


if __name__ == "__main__":
    main()
