# ============================================
# Multi-Agent Tutorial Environment Variables
# ============================================
# Copy this file to .env and fill in your values
# cp .env.example .env

# ============================================
# LLM API Keys (choose your providers)
# ============================================

# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Google Gemini
GOOGLE_API_KEY=your-google-api-key-here

# Azure OpenAI (if using Azure)
AZURE_OPENAI_API_KEY=your-azure-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-02-01

# ============================================
# Local LLM (Ollama)
# ============================================

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ============================================
# Observability & Tracing
# ============================================

# LangSmith (recommended for debugging)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__your-langsmith-key
LANGCHAIN_PROJECT=multiagent-tutorial

# Arize Phoenix
PHOENIX_API_KEY=your-phoenix-key

# ============================================
# Docker Configuration
# ============================================

DOCKER_HOST=unix:///var/run/docker.sock
SANDBOX_TIMEOUT=300
SANDBOX_MEMORY_LIMIT=512m
SANDBOX_CPU_LIMIT=1.0

# ============================================
# Agent Configuration
# ============================================

# Default LLM provider: openai, anthropic, ollama
DEFAULT_LLM_PROVIDER=openai

# Critic Agent settings
CRITIC_MAX_ITERATIONS=5
CRITIC_APPROVAL_THRESHOLD=0.8

# ============================================
# Application Settings
# ============================================

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Workspace path for agent operations
WORKSPACE_PATH=./workspace
